# slide_4PixelNN
Simple NN - with Back Propagation - Swedish (highschool)

Gymnasiekurs för 1:or (fast med matte lite högre), i två delar. Jag tar exemplet om en enda neuron, utan aktiverinsgsfunktion,
och visar hur även något sådant enkelt kan åstadkomma åtminstone något liknaknde y = kx + m, i form av anpassning
á la linjär regression.

I uppföljningen provar vi en fyravärdig vektor som input i syfte att träna ett nätverk att skilja mellan de enklaste
mönster, typ vertikal, horisontell, diagonal eller enfärgad. 

Försök görs att förklara "back propagation" för elever som ännu inte vet vad derivering innebär, än mindre 
kedjeregeln (matte 4).

Fungerande kod och presentaion, till vad som skulle kunna vara en två-månaders kurs. Välkommna att ta o använda själv
Hör av er ifall frågor osv :)

Hälsningar

Ulf

PS O ja just det ... Klicka på NNforts_4px.html (med länk bakåt) för hela. Annars finns även ipynb-filerna var för sig
